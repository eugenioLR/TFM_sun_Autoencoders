{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import sunpy.map\n",
    "import cv2\n",
    "import skimage\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn_image as isns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import autoenc_model as aem\n",
    "import data_generator as dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images\n",
    "AIA193_2016 = sunpy.map.Map(\"data/aia_193A/2016-01*.fits\")\n",
    "AIA193_2016_matrix = np.array(list(d.data for d in AIA193_2016))\n",
    "\n",
    "\n",
    "# Normalize images\n",
    "min_values = AIA193_2016_matrix.min(axis=2).min(axis=1)\n",
    "max_values = AIA193_2016_matrix.max(axis=2).max(axis=1)\n",
    "\n",
    "rg = max_values - min_values\n",
    "rg = np.maximum(rg, 1e-4*np.ones(rg.shape)).reshape([-1,1,1])\n",
    "\n",
    "AIA193_2016_mnorm = (AIA193_2016_matrix-min_values.reshape([-1,1,1])) / rg\n",
    "\n",
    "\n",
    "# Discretize images to detect faulty data\n",
    "AIA193_2016_bytes = np.round(AIA193_2016_mnorm*255).astype(np.uint8)\n",
    "\n",
    "\n",
    "# Calculate histograms\n",
    "nbins = 10\n",
    "hist_vectors = np.array([np.histogram(i.flatten(), bins=np.linspace(0,256,nbins))[0] for i in AIA193_2016_bytes])\n",
    "\n",
    "\n",
    "# Cluster histograms\n",
    "kmeans = KMeans(n_clusters=2, n_init=10)\n",
    "kmeans.fit(hist_vectors/hist_vectors.max())\n",
    "\n",
    "class1 = AIA193_2016_bytes[kmeans.labels_ == kmeans.labels_[0], :, :]\n",
    "class2 = AIA193_2016_bytes[kmeans.labels_ != kmeans.labels_[0], :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isns.ImageGrid([i for i in class1[:9]], cmap=\"afmhot\") # class2 is (probably) noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_input = AIA193_2016_mnorm[kmeans.labels_ == kmeans.labels_[0], :, :]\n",
    "clean_input_train, clean_input_test = train_test_split(clean_input, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_img = keras.Input(shape=[256,256,1])\n",
    "# latent_size = 64\n",
    "\n",
    "# # lrelu = layers.LeakyReLU(0.2)\n",
    "# optim = keras.optimizers.Adam(0.001)\n",
    "# # optim = keras.optimizers.SGD(0.001)\n",
    "# loss = \"mse\"\n",
    "\n",
    "\n",
    "# #x = layers.Reshape([256,256,1])(input_img)\n",
    "# x = input_img\n",
    "# x = layers.Conv2D(8, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.Conv2D(8, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.MaxPooling2D()(x)\n",
    "\n",
    "# x = layers.Conv2D(16, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.Conv2D(16, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.MaxPooling2D()(x)\n",
    "\n",
    "# x = layers.Conv2D(32, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.Conv2D(32, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.MaxPooling2D()(x)\n",
    "\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dropout(0.2)(x)\n",
    "# x = layers.Dense(128, activation=\"relu\")(x)\n",
    "# x = layers.Dropout(0.1)(x)\n",
    "# encoded = layers.Dense(code_size, activation=\"sigmoid\")(x)\n",
    "\n",
    "# x = layers.Dense(256, activation=\"relu\")(encoded)\n",
    "\n",
    "# x = layers.Reshape([8, 8, 4])(x)\n",
    "# x = layers.UpSampling2D()(x)\n",
    "\n",
    "# x = layers.Conv2D(64, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding='same', strides=2)(x)\n",
    "\n",
    "# x = layers.Conv2D(32, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.Conv2DTranspose(32, 3, activation=\"relu\", padding='same', strides=2)(x)\n",
    "\n",
    "# x = layers.Conv2D(16, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.Conv2DTranspose(16, 3, activation=\"relu\", padding='same', strides=2)(x)\n",
    "\n",
    "# x = layers.Conv2D(16, 3, activation=\"relu\", padding='same', strides=1)(x)\n",
    "# x = layers.Conv2DTranspose(1, 3, activation=\"relu\", padding='same', strides=2)(x)\n",
    "\n",
    "# #decoded = layers.Reshape([256,256])(x)\n",
    "# decoded = x\n",
    "\n",
    "\n",
    "# encoder = keras.Model(input_img, encoded)\n",
    "# decoder = keras.Model(encoded, decoded)\n",
    "# print(encoder.summary())\n",
    "# decoder.summary()\n",
    "\n",
    "\n",
    "# autoencoder = keras.Model(input_img, decoder(encoder(input_img)))\n",
    "# autoencoder.compile(loss=loss, optimizer=optim, metrics=[\"mae\"])\n",
    "# autoencoder.summary()\n",
    "\n",
    "latent_size = 96\n",
    "autoencoder, encoder, decoder = aem.gen_autoenc_model(latent_size, optim=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "batch_size = 256\n",
    "\n",
    "history = autoencoder.fit(clean_input, epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_input.testing = True\n",
    "autoencoder.evaluate(clean_input)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "#plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(dg)\n",
    "\n",
    "\n",
    "#idx = np.random.permutation(80)[:5]\n",
    "\n",
    "#example = clean_input_test[idx, :, :]\n",
    "#example = clean_input[0][idx]\n",
    "#print(example.shape)\n",
    "clean_input = dg.SunImgAEGenerator(\"data/aia_193A/\", max_values, min_values, 256, test_split=0.2, shuffle=True)\n",
    "example = clean_input.sample(5)\n",
    "code = encoder.predict(example)\n",
    "reconstructed = decoder(code)\n",
    "\n",
    "images_zipped = [i for i in zip(code, example, reconstructed)]\n",
    "images = []\n",
    "\n",
    "for i in images_zipped:\n",
    "    images.append(np.reshape(i[0], [4,16]))\n",
    "    images.append(np.squeeze(i[1]))\n",
    "    images.append(np.squeeze(i[2]))\n",
    "    \n",
    "\n",
    "isns.ImageGrid(images, cmap=\"afmhot\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = np.random.normal(0, 1, [6, 64])\n",
    "reconstructed = decoder(code)\n",
    "\n",
    "images_zipped = [i for i in zip(code, reconstructed)]\n",
    "images = []\n",
    "\n",
    "for i in images_zipped:\n",
    "    images.append(np.reshape(i[0], [4,16]))\n",
    "    images.append(np.squeeze(i[1]))\n",
    "    \n",
    "\n",
    "isns.ImageGrid(images, cmap=\"afmhot\", vmin=0, vmax=1, col_wrap=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
